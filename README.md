# Reinfocement Learning Classes repository
This is the repository with the tasks from my Reinfocement Learning course. All the tasks are implemented in Python, most in Jupyter Notebooks. To solve the majority of the tasks it is recommended to listen to the lecture or watch the corresponding YouTube Video.

In my course I am based on the great [*Reinforcement Learning: An Introduction* by R. S Sutton and A. G. Barto]( http://incompleteideas.net/book/the-book.html) book.

Another great resources are:
- [Reinfocement Learning Coursera Specialization](https://www.coursera.org/specializations/reinforcement-learning). A very good Coursera specialization that introduces reinforcement learning. I highly recommend it if you want to start your adventure with RL.
- [Deep Renfiforcement Learning Udacity Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893). A bit more advanced but yet a great learning place. As a first RL course it may be difficult, but if you want to study deeper (and are willing to pay for it) this is a place for you.

### Solutions
Generally speaking I am not publishing solutions here. If you need my solutions, feel free to contact me via e-mail.

### Current content (in learning order)
- `kArmedBandit` - implementation of three basic agents (e-Greedy, Optimistic, and UCB) for estimating state-action values in k-Armed Bandit problem.
- `DynamicProgramming` - a Dynamic Programming for a Maze environment (environment is also in this folder)
- `MonteCarlo` - A Monte Carlo for the OpenAI [Black Jack environment](https://www.gymlibrary.dev/environments/toy_text/blackjack/)
- `TD_0` - A Monte Carlo and TD(0) for the [Gym Walking](https://github.com/PrzemekSekula/gym-walking) environment
- `QLearning` - SARSA and Q-learning for both [Cliff Walking](https://www.gymlibrary.dev/environments/toy_text/cliff_walking/) and [Taxi](https://www.gymlibrary.dev/environments/toy_text/taxi/) environments
- `DQLearning` - Deep Q Learning. For now only with the [Cart Pole](https://www.gymlibrary.dev/environments/classic_control/cart_pole/) (upgrades soon)





### Disclamers 
This repository is under construction, new content will appear continuously. 

Although I'll do my best to mark every place where I am using someone's else ideas, sometimes it may be hard. I have a lot of code that I implemented learning from other courses, and I am not sure if I remember where did I take all my code and ideas from. If you feel that I missed any references, please, let me know.

This repository is only a part of the course, prepared for sharing with my students. Feel free to use it as you wish, but without the rest of the course, it may not be so useful for you.